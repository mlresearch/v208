---
title: Continually Updating Neural Causal Models
abstract: A common assumption in causal modelling is that the relations between variables
  are fixed mechanisms. But in reality, these mechanisms often change over time and
  new data might not fit the original model as well. But is it reasonable to regularly
  train new models or can we update a single model continually instead? We propose
  utilizing the field of continual learning to help keep causal models updated over
  time.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: busch23a
month: 0
tex_title: Continually Updating Neural Causal Models
firstpage: 30
lastpage: 37
page: 30-37
order: 30
cycles: false
bibtex_author: Busch, Florian Peter and Seng, Jonas and Willig, Moritz and Ze\v{c}evi\'c,
  Matej
author:
- given: Florian Peter
  family: Busch
- given: Jonas
  family: Seng
- given: Moritz
  family: Willig
- given: Matej
  family: Zečević
date: 2023-06-04
address: 
container-title: Proceedings of The First AAAI Bridge Program on Continual Causality
volume: '208'
genre: inproceedings
issued:
  date-parts:
  - 2023
  - 6
  - 4
pdf: https://proceedings.mlr.press/v208/busch23a/busch23a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
